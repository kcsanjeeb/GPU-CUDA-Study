{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Matrix Multiplication: Naive, Optimized, and CUDA Approaches",
   "id": "52e1b9ad3f0eef6a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Matrix multiplication is a more complex operation than matrix addition. Given two matrices A of dimensions m ×n and B of dimensions n ×p, their product C is computed as:\n",
    "\n",
    "### Naive Implementation of Matrix Multiplication"
   ],
   "id": "119d0bf06ed79d91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T03:00:39.378059Z",
     "start_time": "2025-09-28T03:00:39.294049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "B = np.array([[7, 8, 9], [10, 11, 12], [13, 14, 15]])\n",
    "\n",
    "# Naive Matrix Multiplication\n",
    "\n",
    "C = np.zeros((A.shape[0], B.shape[1]))\n",
    "\n",
    "for i in range(A.shape[0]):\n",
    "    for j in range(B.shape[1]):\n",
    "        for k in range(A.shape[1]):\n",
    "            C[i, j] = A[i, k] * B[k, j]\n",
    "\n",
    "print(C)\n"
   ],
   "id": "6e77381025ba80f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39. 42. 45.]\n",
      " [78. 84. 90.]]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Naive Matrix Multiplication\n",
    "The naive approach to matrix multiplication involves three nested loops: one for rows of matrix A,\n",
    "one for columns of matrix B, and one for summing the element-wise products. Here’s how you can\n",
    "implement this in Python:"
   ],
   "id": "94682dc813afed72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T03:03:43.943717Z",
     "start_time": "2025-09-28T03:03:43.935797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def naive_matrix_multiplication(A, B):\n",
    "    m,n = A.shape\n",
    "    n,p = B.shape\n",
    "    C = np.zeros((m,p))\n",
    "    for i in range(m):\n",
    "        for j in range(p):\n",
    "            for k in range(n):\n",
    "                C[i, j] = A[i, k] * B[k, j]\n",
    "    return C\n",
    "\n",
    "# Define two matrices\n",
    "A = np.array([[1, 2], [4, 5]])\n",
    "B = np.array([[7, 8 ], [10, 11]])\n",
    "\n",
    "C = naive_matrix_multiplication(A, B)\n",
    "print(C)"
   ],
   "id": "b59e40592b77e2d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20. 22.]\n",
      " [50. 55.]]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Optimized Matrix Multiplication\n",
    "The naive matrix multiplication is inefficient because it repeatedly reads the same data from memory, causing memory latency issues. A more optimized approach involves using shared memory and leveraging matrix libraries like NumPy, which are highly optimized and make use of BLAS (Basic Linear Algebra Subprograms)\n",
    "\n",
    "### Using NumPy for Optimized Multiplication\n",
    "NumPy’s dot function is a highly optimized implementation of matrix multiplication."
   ],
   "id": "32c34945a7eba663"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T03:05:01.021209Z",
     "start_time": "2025-09-28T03:05:01.015396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 2], [4, 5]])\n",
    "B = np.array([[7, 8 ], [10, 11]])\n",
    "\n",
    "C = np.dot(A, B)\n",
    "print(C)"
   ],
   "id": "9592960da4e2fa4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27 30]\n",
      " [78 87]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "NumPy uses highly optimized libraries under the hood (like OpenBLAS or Intel MKL) to perform\n",
    "matrix multiplication efficiently, taking advantage of low-level optimizations such as data pre-fetching\n",
    "and cache reuse."
   ],
   "id": "e79da0704d07023f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parallelizing Matrix Multiplication\n",
    "To parallelize matrix multiplication manually, we can break the operation down by assigning different rows of matrix A and different columns of matrix B to different threads. However, using optimized libraries like NumPy is often the best approach, as they already include multi-threading and SIMD (Single Instruction, Multiple Data) optimizations.\n",
    "Here’s an example of manually parallelizing matrix multiplication:"
   ],
   "id": "3bb75ad0b01cfa03"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-28T04:47:27.197250Z",
     "start_time": "2025-09-28T04:47:27.125568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute one row of matrix C\n",
    "def multiply_row(A_row, B):\n",
    "    return np.dot(A_row, B)\n",
    "\n",
    "# Parallel Matrix Multiplication\n",
    "def parallel_matrix_multiplication(A, B):\n",
    "    m = A.shape[0]\n",
    "    C = np.zeros((m,B.shape[1]))\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(multiply_row, A, [B]*m))\n",
    "\n",
    "    return np.array(results)\n",
    "\n",
    "A = np.array([[1, 2], [4, 5]])\n",
    "B = np.array([[7, 8 ], [10, 11]])\n",
    "\n",
    "C = parallel_matrix_multiplication(A, B)\n",
    "print(C)"
   ],
   "id": "6209af7e80aba5a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27 30]\n",
      " [78 87]]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1. Work Division by Rows\n",
    "* Each thread processes one complete row of the result matrix\n",
    "* The thread takes a single row from A and multiplies it with the entire matrix B\n",
    "* This is an embarrassingly parallel problem - each row can be computed independently\n",
    "#### 2. Thread Pool Execution\n",
    "* `ThreadPoolExecutor` creates a pool of worker threads (typically one per CPU core)\n",
    "* `executor.map()` distributes the rows across available threads\n",
    "* `[B]*m` creates `m` copies of matrix B (one for each thread)\n",
    "#### Execution Visualization\n",
    "```\n",
    "A = [[1, 2],    B = [[7,  8],\n",
    "     [4, 5]]         [10, 11]]\n",
    "\n",
    "THREAD 1: Process row 0\n",
    "A[0] = [1, 2] × B = [1*7 + 2*10, 1*8 + 2*11] = [27, 30]\n",
    "\n",
    "THREAD 2: Process row 1\n",
    "A[1] = [4, 5] × B = [4*7 + 5*10, 4*8 + 5*11] = [78, 87]\n",
    "\n",
    "Final result: [[27, 30],\n",
    "               [78, 87]]\n",
    "```"
   ],
   "id": "f59052f4d6c03806"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Memory Coalescing and Alignment\n",
    "Memory coalescing is a technique that ensures efficient memory access by aligning threads’ memory\n",
    "requests into fewer transactions. When threads in a warp (a group of 32 threads in CUDA) access consecutive memory addresses, the GPU can combine these accesses into fewer, larger memory transactions. This maximizes memory bandwidth utilization and reduces the overall memory latency.\n",
    "How it works: In CUDA, global memory is accessed by all threads, but accessing it efficiently is\n",
    "key to performance. Without proper coalescing, each thread might make its own memory request,\n",
    "leading to multiple, inefficient transactions. With memory coalescing, these requests are combined\n",
    "into a single transaction when:\n",
    "* Threads in a warp access consecutive addresses.\n",
    "* The starting address is properly aligned.\n",
    "* Ensuring proper alignment: To achieve memory coalescing, we need to ensure proper alignment\n",
    "of memory. The memory addresses accessed by each thread should be aligned to the size of the data\n",
    "type. For example, for an array of ‘float‘ (4 bytes), the address should be aligned on a 4-byte boundary.\n",
    "This alignment allows the GPU to fetch data in a single coalesced transaction.\n",
    "\n",
    "An example of memory coalescing with a properly aligned float array:\n",
    "```\n",
    "__global__ void coalescedMemoryAccess(float *input, float *output){\n",
    "    int tid = threadId.x + blockId.x * blockDim.x;\n",
    "    output[tid] = input[tid]\n",
    "}\n",
    "```\n",
    "In this case, assuming the ‘input‘ and ‘output‘ arrays are properly aligned, memory access will be\n",
    "coalesced."
   ],
   "id": "320865c1583e0aae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Shared Memory Optimization\n",
    "Shared memory is a small, fast, on-chip memory that can be used to significantly speed up access\n",
    "times in CUDA programs. Shared memory is accessible by all threads within a block, making it useful\n",
    "for data that needs to be accessed multiple times by different threads.\n",
    "Key advantages of shared memory:\n",
    "* Much faster than global memory.\n",
    "* Reduces redundant global memory accesses.\n",
    "* Allows efficient data sharing between threads within a block.\n",
    "\n",
    "* To use shared memory effectively, we need to:\n",
    "    * Load frequently accessed data from global memory into shared memory.\n",
    "    * Minimize bank conflicts (situations where multiple threads attempt to access the same memory bank simultaneously).\n",
    "\n",
    "**Bank conflicts:** CUDA shared memory is divided into banks, and if multiple threads try to access data in the same bank at the same time, a bank conflict occurs, leading to serialization and performance loss. To avoid this, ensure that threads access different memory banks, ideally by organizing data such that consecutive threads access consecutive addresses."
   ],
   "id": "2da23f518e7b4c0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Reducing Warp Divergence for Performance\n",
    "Warp divergence occurs when threads in a warp follow different execution paths due to conditional\n",
    "branching (e.g., ‘if-else‘ statements). When divergence occurs, the GPU must execute both paths seri-\n",
    "ally, which reduces overall performance.\n",
    "How to minimize warp divergence:\n",
    "1. Avoid branching whenever possible, or minimize its occur-\n",
    "rence by structuring code carefully.\n",
    "2. Use predication (conditional assignments) instead of branching,\n",
    "which allows all threads to execute the same instruction with different outcomes based on conditions.\n",
    "3. Ensure branch conditions are uniform across threads in a warp, meaning all threads either take the\n",
    "same branch or none of them do."
   ],
   "id": "5e0639720a99b4bb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Warp Divergence Explained\n",
    "### The Problem\n",
    "```\n",
    "__global__ void warpDivergenceExample(int *input, int *output) {\n",
    "    int tid = threadIdx.x;\n",
    "    if (input[tid] > 0) {\n",
    "        output[tid] = input[tid] * 2;  // Path A\n",
    "    } else {\n",
    "        output[tid] = input[tid] / 2;  // Path B\n",
    "    }\n",
    "}\n",
    "```\n",
    "#### What happens when threads in a warp have different conditions:\n",
    "```\n",
    "Warp with 8 threads (simplified example):\n",
    "Thread:   0   1   2   3   4   5   6   7\n",
    "Input:   [5, -2,  8, -1,  3, -4,  7, -3]\n",
    "Condition: T   F   T   F   T   F   T   F  (T = input[tid] > 0)\n",
    "```\n",
    "**Execution:**\n",
    "1. Threads 0,2,4,6 take TRUE branch → execute multiplication\n",
    "2. Threads 1,3,5,7 take FALSE branch → execute division\n",
    "3. GPU must execute BOTH paths SERIALLY for the same warp!\n",
    "\n",
    "**Performance Impact**\n",
    "```\n",
    "Without divergence: 32 threads execute 1 instruction → 1 cycle\n",
    "With divergence: 32 threads execute 2 paths → 2 cycles (100% slower!)\n",
    "```\n",
    "### Visualizing Warp Divergence\n",
    "#### Divergent Warp Execution\n",
    "```\n",
    "Warp Timeline (BAD - With Divergence):\n",
    "Cycle 1: [T][T][T][T][F][F][F][F] ← Threads 0-3: Execute TRUE path\n",
    "         Threads 4-7: IDLE (masked out)\n",
    "\n",
    "Cycle 2: [I][I][I][I][T][T][T][T] ← Threads 4-7: Execute FALSE path\n",
    "         Threads 0-3: IDLE (masked out)\n",
    "\n",
    "Total: 2 cycles for 8 threads\n",
    "```\n",
    "#### Uniform Warp Execution (Ideal)\n",
    "```\n",
    "Warp Timeline (GOOD - No Divergence):\n",
    "Cycle 1: [T][T][T][T][T][T][T][T] ← All threads execute same path\n",
    "Total: 1 cycle for 8 threads (2x faster!)\n",
    "```\n",
    "## The Solution: Predication\n",
    "#### Using Ternary Operator for Predication\n",
    "```\n",
    "__global__ void warpDivergenceAvoided(int *input, int *output) {\n",
    "    int tid = threadIdx.x;\n",
    "    int value = input[tid];\n",
    "    output[tid] = (value > 0) ? value * 2 : value / 2;\n",
    "}\n",
    "```\n",
    "#### How predication works:\n",
    "* All threads execute both the multiplication and division instructions\n",
    "* Conditional selection happens at the register level, not branch level\n",
    "* No branching = no serial execution of different paths\n"
   ],
   "id": "447ffe5cd8b03608"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a3a6da36145acfc4"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
